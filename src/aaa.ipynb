{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loading data...\n",
      "\n",
      "[2] Simple EDA...\n",
      "Train shape: (256351, 69)\n",
      "Test shape: (90067, 68)\n",
      "\n",
      "Target distribution in train data (임신 성공 여부):\n",
      "임신 성공 여부\n",
      "0    0.741651\n",
      "1    0.258349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values in train (Top 5):\n",
      "난자 해동 경과일                254915\n",
      "PGS 시술 여부                254422\n",
      "PGD 시술 여부                254172\n",
      "착상 전 유전 검사 사용 여부         253633\n",
      "임신 시도 또는 마지막 임신 경과 연수    246981\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test (Top 5):\n",
      "난자 해동 경과일                89575\n",
      "PGS 시술 여부                89396\n",
      "PGD 시술 여부                89286\n",
      "착상 전 유전 검사 사용 여부         89134\n",
      "임신 시도 또는 마지막 임신 경과 연수    86770\n",
      "dtype: int64\n",
      "\n",
      "[3] Data Preprocessing...\n",
      "\n",
      "[4] Splitting data into train/validation...\n",
      "X_train shape: (205080, 61)\n",
      "X_val shape: (51271, 61)\n",
      "\n",
      "[5] Training LightGBM model...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 52982, number of negative: 152098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 686\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 59\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.7352\tvalid_0's binary_logloss: 0.492228\n",
      "[200]\tvalid_0's auc: 0.736546\tvalid_0's binary_logloss: 0.489849\n",
      "[300]\tvalid_0's auc: 0.736955\tvalid_0's binary_logloss: 0.489601\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's auc: 0.737004\tvalid_0's binary_logloss: 0.489578\n",
      "\n",
      "[6] Evaluation on validation set...\n",
      "Validation AUC: 0.7370\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7559    0.9704    0.8498     38025\n",
      "           1     0.5412    0.1002    0.1691     13246\n",
      "\n",
      "    accuracy                         0.7456     51271\n",
      "   macro avg     0.6485    0.5353    0.5094     51271\n",
      "weighted avg     0.7004    0.7456    0.6739     51271\n",
      "\n",
      "\n",
      "[7] Hyperparameter Tuning with GridSearchCV...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.180426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35321, number of negative: 101399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258346 -> initscore=-1.054586\n",
      "[LightGBM] [Info] Start training from score -1.054586\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35322, number of negative: 101398\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 136720, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054547\n",
      "[LightGBM] [Info] Start training from score -1.054547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 52982, number of negative: 152098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 686\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Best Params: {'colsample_bytree': 0.8, 'max_depth': 7, 'min_child_samples': 50, 'num_leaves': 31, 'subsample': 0.8}\n",
      "Best AUC: 0.739551879681939\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 52982, number of negative: 152098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 686\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 59\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.735429\tvalid_0's binary_logloss: 0.492467\n",
      "[200]\tvalid_0's auc: 0.736916\tvalid_0's binary_logloss: 0.489596\n",
      "[300]\tvalid_0's auc: 0.737278\tvalid_0's binary_logloss: 0.489309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's auc: 0.737368\tvalid_0's binary_logloss: 0.489253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid_0's auc: 0.737422\tvalid_0's binary_logloss: 0.489222\n",
      "\n",
      "[8] Final Inference & Create Submission File...\n",
      "Submission saved -> /Users/chelsey/Desktop/project/lgaimers/tab-transformer-pytorch/data/sample_submission.csv\n",
      "\n",
      "[9] Plot Feature Importances...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def add_unknown_and_fit_encoder(series: pd.Series, le: LabelEncoder):\n",
    "    \"\"\"\n",
    "    주어진 series(범주형)에 있는 유니크 값들과 \"unknown\" 범주를 합쳐서\n",
    "    LabelEncoder를 fit한다.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    le: fit이 완료된 LabelEncoder\n",
    "    \"\"\"\n",
    "    orig_cats = series.dropna().unique().tolist()\n",
    "    if \"unknown\" not in orig_cats:\n",
    "        orig_cats.append(\"unknown\")\n",
    "    le.fit(orig_cats)\n",
    "    return le\n",
    "\n",
    "\n",
    "def transform_with_unknown(series: pd.Series, le: LabelEncoder):\n",
    "    \"\"\"\n",
    "    이미 fit된 LabelEncoder(le)를 사용해 series에 있는 범주를 인코딩.\n",
    "    만약 le.classes_에 없는 값이 발견되면 \"unknown\"으로 대체 후 transform.\n",
    "    \"\"\"\n",
    "    known_cats = set(le.classes_)\n",
    "    def map_unknown(x):\n",
    "        return x if x in known_cats else \"unknown\"\n",
    "    series_mapped = series.fillna(\"unknown\").apply(map_unknown)\n",
    "    encoded = le.transform(series_mapped)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def preprocess_train(df_train):\n",
    "    \"\"\"\n",
    "    [사용자 제공 전처리 로직]을 학습 데이터에 적용.\n",
    "    LabelEncoder와 MinMaxScaler는 fit_transform까지 수행.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_preprocessed: 전처리 완료된 DataFrame (타깃 포함 상태)\n",
    "    label_encoders: 각 범주형 변수별 LabelEncoder dictionary\n",
    "    minmax_scaler: MinMaxScaler 객체\n",
    "    dropped_columns: 전처리 중 제거된 컬럼 목록 (테스트 전처리에 사용)\n",
    "    \"\"\"\n",
    "    # ================================ #\n",
    "    # 1. 명시적으로 제거할 열 (NaN이 많다는 이유 등)\n",
    "    # ================================ #\n",
    "    cols_to_drop_explicit = [\"난자 채취 경과일\", \"난자 혼합 경과일\"]\n",
    "    for c in cols_to_drop_explicit:\n",
    "        if c in df_train.columns:\n",
    "            df_train.drop(columns=[c], inplace=True)\n",
    "    \n",
    "    # ================================ #\n",
    "    # 2. 수치형 변수 변환 (to_numeric) 및 결측치 처리\n",
    "    # ================================ #\n",
    "    numerical_columns = [\n",
    "        \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "        \"총 생성 배아 수\",\n",
    "        \"미세주입된 난자 수\",\n",
    "        \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\",\n",
    "        \"미세주입 배아 이식 수\",\n",
    "        \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\",\n",
    "        \"해동된 배아 수\",\n",
    "        \"해동 난자 수\",\n",
    "        \"수집된 신선 난자 수\",\n",
    "        \"저장된 신선 난자 수\",\n",
    "        \"혼합된 난자 수\",\n",
    "        \"파트너 정자와 혼합된 난자 수\",\n",
    "        \"기증자 정자와 혼합된 난자 수\",\n",
    "        \"난자 해동 경과일\",\n",
    "        \"배아 이식 경과일\",\n",
    "        \"배아 해동 경과일\"\n",
    "    ]\n",
    "    for col in numerical_columns:\n",
    "        if col in df_train.columns:\n",
    "            df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "    \n",
    "    # DI 시술과 무관한 항목 → 결측치 0 처리\n",
    "    cols_di = [\n",
    "        '단일 배아 이식 여부',\n",
    "        '착상 전 유전 진단 사용 여부',\n",
    "        '배아 생성 주요 이유',\n",
    "        '총 생성 배아 수',\n",
    "        '미세주입된 난자 수',\n",
    "        '미세주입에서 생성된 배아 수',\n",
    "        '이식된 배아 수',\n",
    "        '미세주입 배아 이식 수',\n",
    "        '저장된 배아 수',\n",
    "        '미세주입 후 저장된 배아 수',\n",
    "        '해동된 배아 수',\n",
    "        '해동 난자 수',\n",
    "        '수집된 신선 난자 수',\n",
    "        '저장된 신선 난자 수',\n",
    "        '혼합된 난자 수',\n",
    "        '파트너 정자와 혼합된 난자 수',\n",
    "        '기증자 정자와 혼합된 난자 수',\n",
    "        '동결 배아 사용 여부',\n",
    "        '신선 배아 사용 여부',\n",
    "        '기증 배아 사용 여부',\n",
    "        '대리모 여부'\n",
    "    ]\n",
    "    condition = df_train[cols_di].isnull().all(axis=1)\n",
    "    cols_to_update = cols_di + [\n",
    "        'PGD 시술 여부', 'PGS 시술 여부',\n",
    "        '난자 해동 경과일',\n",
    "        '배아 이식 경과일', '배아 해동 경과일'\n",
    "    ]\n",
    "    df_train.loc[condition, cols_to_update] = 0\n",
    "    df_train[cols_di] = df_train[cols_di].fillna(0)\n",
    "    if '배아 이식 경과일' in df_train.columns:\n",
    "        df_train['배아 이식 경과일'] = df_train['배아 이식 경과일'].fillna(5.0)\n",
    "    \n",
    "    # ================================ #\n",
    "    # 3. 범주형 변수 Label Encoding (unknown 처리 포함)\n",
    "    # ================================ #\n",
    "    categorical_columns = [\n",
    "        \"시술 시기 코드\",\n",
    "        \"시술 당시 나이\",\n",
    "        \"시술 유형\",\n",
    "        \"특정 시술 유형\",\n",
    "        \"배란 자극 여부\",\n",
    "        \"배란 유도 유형\",\n",
    "        \"단일 배아 이식 여부\",\n",
    "        \"착상 전 유전 검사 사용 여부\",\n",
    "        \"착상 전 유전 진단 사용 여부\",\n",
    "        \"남성 주 불임 원인\",\n",
    "        \"남성 부 불임 원인\",\n",
    "        \"여성 주 불임 원인\",\n",
    "        \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\",\n",
    "        \"부부 부 불임 원인\",\n",
    "        \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\",\n",
    "        \"불임 원인 - 남성 요인\",\n",
    "        \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 자궁경부 문제\",\n",
    "        \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\",\n",
    "        \"불임 원인 - 정자 면역학적 요인\",\n",
    "        \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\",\n",
    "        \"배아 생성 주요 이유\",\n",
    "        \"총 시술 횟수\",\n",
    "        \"클리닉 내 총 시술 횟수\",\n",
    "        \"IVF 시술 횟수\",\n",
    "        \"DI 시술 횟수\",\n",
    "        \"총 임신 횟수\",\n",
    "        \"IVF 임신 횟수\",\n",
    "        \"DI 임신 횟수\",\n",
    "        \"총 출산 횟수\",\n",
    "        \"IVF 출산 횟수\",\n",
    "        \"DI 출산 횟수\",\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "        \"동결 배아 사용 여부\",\n",
    "        \"신선 배아 사용 여부\",\n",
    "        \"기증 배아 사용 여부\",\n",
    "        \"대리모 여부\",\n",
    "        \"PGD 시술 여부\",\n",
    "        \"PGS 시술 여부\",\n",
    "        \"임신 성공 여부\"\n",
    "    ]\n",
    "    \n",
    "    # '총 생성 배아 수'가 0인 행 → PGD, PGS 시술 여부 0 처리\n",
    "    cond_zero = (df_train['총 생성 배아 수'] == 0)\n",
    "    if 'PGD 시술 여부' in df_train.columns and 'PGS 시술 여부' in df_train.columns:\n",
    "        df_train.loc[cond_zero, ['PGD 시술 여부', 'PGS 시술 여부']] = 0\n",
    "    # 불임 원인 - 여성 요인 제거 (카디널리티가 1인 경우)\n",
    "    if \"불임 원인 - 여성 요인\" in df_train.columns:\n",
    "        df_train.drop(columns=[\"불임 원인 - 여성 요인\"], inplace=True)\n",
    "    \n",
    "    # --- 기존 LabelEncoder 대신 \"unknown\" 처리 함수 사용 ---\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        if col in df_train.columns:\n",
    "            df_train[col] = df_train[col].astype(str)\n",
    "            le = LabelEncoder()\n",
    "            le = add_unknown_and_fit_encoder(df_train[col], le)\n",
    "            df_train[col] = transform_with_unknown(df_train[col], le)\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # ================================ #\n",
    "    # 4. 결측치 비율이 높은 열 삭제\n",
    "    # ================================ #\n",
    "    missing_counts = df_train.isnull().sum()\n",
    "    missing_ratio = (missing_counts / len(df_train)) * 100\n",
    "    threshold = 80.0\n",
    "    high_missing_cols = missing_ratio[missing_ratio >= threshold].index\n",
    "    df_train.drop(columns=high_missing_cols, inplace=True, errors='ignore')\n",
    "    dropped_columns = list(high_missing_cols) + list(cols_to_drop_explicit)\n",
    "    \n",
    "    # ================================ #\n",
    "    # 5. MinMaxScaler 적용\n",
    "    # ================================ #\n",
    "    cols_to_scale = [\n",
    "        \"총 생성 배아 수\",\n",
    "        \"미세주입된 난자 수\",\n",
    "        \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\",\n",
    "        \"미세주입 배아 이식 수\",\n",
    "        \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\",\n",
    "        \"해동된 배아 수\",\n",
    "        \"혼합된 난자 수\",\n",
    "        \"수집된 신선 난자 수\",\n",
    "        \"저장된 신선 난자 수\",\n",
    "        \"배아 이식 경과일\",\n",
    "        \"파트너 정자와 혼합된 난자 수\",\n",
    "        \"기증자 정자와 혼합된 난자 수\"\n",
    "    ]\n",
    "    cols_to_scale = [c for c in cols_to_scale if c in df_train.columns]\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    df_train[cols_to_scale] = minmax_scaler.fit_transform(df_train[cols_to_scale])\n",
    "    \n",
    "    return df_train, label_encoders, minmax_scaler, dropped_columns\n",
    "\n",
    "\n",
    "def preprocess_test(df_test, label_encoders, minmax_scaler, dropped_columns):\n",
    "    \"\"\"\n",
    "    학습 데이터에서 fit된 LabelEncoder, MinMaxScaler 정보를 사용하여\n",
    "    테스트 데이터에 동일 전처리(transform)만 수행한다.\n",
    "    \"\"\"\n",
    "    # 1. 명시적으로 제거할 열 (학습과 동일)\n",
    "    for c in [\"난자 채취 경과일\", \"난자 혼합 경과일\"]:\n",
    "        if c in df_test.columns:\n",
    "            df_test.drop(columns=[c], inplace=True)\n",
    "    \n",
    "    # 2. 수치형 변수 변환\n",
    "    numerical_columns = [\n",
    "        \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "        \"총 생성 배아 수\",\n",
    "        \"미세주입된 난자 수\",\n",
    "        \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\",\n",
    "        \"미세주입 배아 이식 수\",\n",
    "        \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\",\n",
    "        \"해동된 배아 수\",\n",
    "        \"해동 난자 수\",\n",
    "        \"수집된 신선 난자 수\",\n",
    "        \"저장된 신선 난자 수\",\n",
    "        \"혼합된 난자 수\",\n",
    "        \"파트너 정자와 혼합된 난자 수\",\n",
    "        \"기증자 정자와 혼합된 난자 수\",\n",
    "        \"난자 해동 경과일\",\n",
    "        \"배아 이식 경과일\",\n",
    "        \"배아 해동 경과일\"\n",
    "    ]\n",
    "    for col in numerical_columns:\n",
    "        if col in df_test.columns:\n",
    "            df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
    "    \n",
    "    # DI 관련 결측치 처리 (학습과 동일)\n",
    "    cols_di = [\n",
    "        '단일 배아 이식 여부',\n",
    "        '착상 전 유전 진단 사용 여부',\n",
    "        '배아 생성 주요 이유',\n",
    "        '총 생성 배아 수',\n",
    "        '미세주입된 난자 수',\n",
    "        '미세주입에서 생성된 배아 수',\n",
    "        '이식된 배아 수',\n",
    "        '미세주입 배아 이식 수',\n",
    "        '저장된 배아 수',\n",
    "        '미세주입 후 저장된 배아 수',\n",
    "        '해동된 배아 수',\n",
    "        '해동 난자 수',\n",
    "        '수집된 신선 난자 수',\n",
    "        '저장된 신선 난자 수',\n",
    "        '혼합된 난자 수',\n",
    "        '파트너 정자와 혼합된 난자 수',\n",
    "        '기증자 정자와 혼합된 난자 수',\n",
    "        '동결 배아 사용 여부',\n",
    "        '신선 배아 사용 여부',\n",
    "        '기증 배아 사용 여부',\n",
    "        '대리모 여부'\n",
    "    ]\n",
    "    common_di_cols = [c for c in cols_di if c in df_test.columns]\n",
    "    condition = df_test[common_di_cols].isnull().all(axis=1) if len(common_di_cols) > 0 else None\n",
    "    cols_to_update = common_di_cols + [\n",
    "        'PGD 시술 여부', 'PGS 시술 여부',\n",
    "        '난자 해동 경과일',\n",
    "        '배아 이식 경과일', '배아 해동 경과일'\n",
    "    ]\n",
    "    cols_to_update = [c for c in cols_to_update if c in df_test.columns]\n",
    "    if condition is not None:\n",
    "        df_test.loc[condition, cols_to_update] = 0\n",
    "    if len(common_di_cols) > 0:\n",
    "        df_test[common_di_cols] = df_test[common_di_cols].fillna(0)\n",
    "    if '배아 이식 경과일' in df_test.columns:\n",
    "        df_test['배아 이식 경과일'] = df_test['배아 이식 경과일'].fillna(5.0)\n",
    "    \n",
    "    # 3. 범주형 변수 Label Encoding (학습 시 fit된 인코더 사용; unseen label → \"unknown\")\n",
    "    categorical_columns = [\n",
    "        \"시술 시기 코드\",\n",
    "        \"시술 당시 나이\",\n",
    "        \"시술 유형\",\n",
    "        \"특정 시술 유형\",\n",
    "        \"배란 자극 여부\",\n",
    "        \"배란 유도 유형\",\n",
    "        \"단일 배아 이식 여부\",\n",
    "        \"착상 전 유전 검사 사용 여부\",\n",
    "        \"착상 전 유전 진단 사용 여부\",\n",
    "        \"남성 주 불임 원인\",\n",
    "        \"남성 부 불임 원인\",\n",
    "        \"여성 주 불임 원인\",\n",
    "        \"여성 부 불임 원인\",\n",
    "        \"부부 주 불임 원인\",\n",
    "        \"부부 부 불임 원인\",\n",
    "        \"불명확 불임 원인\",\n",
    "        \"불임 원인 - 난관 질환\",\n",
    "        \"불임 원인 - 남성 요인\",\n",
    "        \"불임 원인 - 배란 장애\",\n",
    "        \"불임 원인 - 자궁경부 문제\",\n",
    "        \"불임 원인 - 자궁내막증\",\n",
    "        \"불임 원인 - 정자 농도\",\n",
    "        \"불임 원인 - 정자 면역학적 요인\",\n",
    "        \"불임 원인 - 정자 운동성\",\n",
    "        \"불임 원인 - 정자 형태\",\n",
    "        \"배아 생성 주요 이유\",\n",
    "        \"총 시술 횟수\",\n",
    "        \"클리닉 내 총 시술 횟수\",\n",
    "        \"IVF 시술 횟수\",\n",
    "        \"DI 시술 횟수\",\n",
    "        \"총 임신 횟수\",\n",
    "        \"IVF 임신 횟수\",\n",
    "        \"DI 임신 횟수\",\n",
    "        \"총 출산 횟수\",\n",
    "        \"IVF 출산 횟수\",\n",
    "        \"DI 출산 횟수\",\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "        \"동결 배아 사용 여부\",\n",
    "        \"신선 배아 사용 여부\",\n",
    "        \"기증 배아 사용 여부\",\n",
    "        \"대리모 여부\",\n",
    "        \"PGD 시술 여부\",\n",
    "        \"PGS 시술 여부\"\n",
    "    ]\n",
    "    if \"불임 원인 - 여성 요인\" in df_test.columns:\n",
    "        df_test.drop(columns=[\"불임 원인 - 여성 요인\"], inplace=True)\n",
    "    for col in categorical_columns:\n",
    "        if col in df_test.columns and col in label_encoders:\n",
    "            df_test[col] = df_test[col].astype(str)\n",
    "            df_test[col] = transform_with_unknown(df_test[col], label_encoders[col])\n",
    "    \n",
    "    # 4. 학습 시 80% 이상 결측치로 제거된 열(dropped_columns)도 test에서 제거\n",
    "    for c in dropped_columns:\n",
    "        if c in df_test.columns:\n",
    "            df_test.drop(columns=[c], inplace=True)\n",
    "    \n",
    "    # 5. MinMaxScaler transform\n",
    "    cols_to_scale = [\n",
    "        \"총 생성 배아 수\",\n",
    "        \"미세주입된 난자 수\",\n",
    "        \"미세주입에서 생성된 배아 수\",\n",
    "        \"이식된 배아 수\",\n",
    "        \"미세주입 배아 이식 수\",\n",
    "        \"저장된 배아 수\",\n",
    "        \"미세주입 후 저장된 배아 수\",\n",
    "        \"해동된 배아 수\",\n",
    "        \"혼합된 난자 수\",\n",
    "        \"수집된 신선 난자 수\",\n",
    "        \"저장된 신선 난자 수\",\n",
    "        \"배아 이식 경과일\",\n",
    "        \"파트너 정자와 혼합된 난자 수\",\n",
    "        \"기증자 정자와 혼합된 난자 수\"\n",
    "    ]\n",
    "    cols_to_scale = [c for c in cols_to_scale if c in df_test.columns]\n",
    "    if len(cols_to_scale) > 0:\n",
    "        df_test[cols_to_scale] = minmax_scaler.transform(df_test[cols_to_scale])\n",
    "    \n",
    "    return df_test\n",
    "\n",
    "\n",
    "###########################\n",
    "# 이하 Main 파이프라인 코드\n",
    "###########################\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    난임 환자 대상 임신 성공 여부 예측 파이프라인\n",
    "    1) EDA\n",
    "    2) 전처리 (사용자 제공 로직 적용)\n",
    "    3) 학습/검증 데이터 분할\n",
    "    4) 모델 학습 (Callback으로 조기 종료)\n",
    "    5) 평가\n",
    "    6) GridSearchCV를 통한 파라미터 튜닝\n",
    "    7) 최적 파라미터로 재학습\n",
    "    8) 테스트 예측 및 제출 파일 생성\n",
    "    9) 피처 중요도 시각화\n",
    "    \"\"\"\n",
    "    # =========================================================================\n",
    "    # 1. 데이터 불러오기\n",
    "    # =========================================================================\n",
    "    print(\"[1] Loading data...\")\n",
    "    train = pd.read_csv(r\"/Users/chelsey/Desktop/project/lgaimers/tab-transformer-pytorch/data/train.csv\")\n",
    "    test = pd.read_csv(r\"/Users/chelsey/Desktop/project/lgaimers/tab-transformer-pytorch/data/test.csv\")\n",
    "    submission = pd.read_csv(r\"/Users/chelsey/Desktop/project/lgaimers/tab-transformer-pytorch/data/sample_submission.csv\")  # 제출 양식\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. 간단한 EDA (탐색적 데이터 분석)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[2] Simple EDA...\")\n",
    "    print(\"Train shape:\", train.shape)\n",
    "    print(\"Test shape:\", test.shape)\n",
    "    target_col = \"임신 성공 여부\"\n",
    "    print(f\"\\nTarget distribution in train data ({target_col}):\")\n",
    "    print(train[target_col].value_counts(normalize=True))\n",
    "    print(\"\\nMissing values in train (Top 5):\")\n",
    "    print(train.isna().sum().sort_values(ascending=False).head(5))\n",
    "    print(\"\\nMissing values in test (Top 5):\")\n",
    "    print(test.isna().sum().sort_values(ascending=False).head(5))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. 데이터 전처리 (학습 데이터에 사용자 제공 로직 적용)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[3] Data Preprocessing...\")\n",
    "    # train 복사본에 대해 전처리 진행 (타깃 포함)\n",
    "    df_train_pre, label_encoders, minmax_scaler, dropped_columns = preprocess_train(train.copy())\n",
    "    # 학습 시 타깃과 피처 분리\n",
    "    # \"ID\" 컬럼은 모델 학습에 필요 없으므로 제거 (에러 방지를 위해)\n",
    "    df_train_pre = df_train_pre.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "    X = df_train_pre.drop(columns=[target_col], errors='ignore')\n",
    "    y_encoded = df_train_pre[target_col]\n",
    "    \n",
    "    # test 데이터 전처리 (학습 시 fit한 인코더, scaler, 제거된 열 정보 사용)\n",
    "    # test 데이터에서도 \"ID\" 컬럼 제거\n",
    "    test = test.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "    X_test_pre = preprocess_test(test.copy(), label_encoders, minmax_scaler, dropped_columns)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. 학습/검증 데이터 분할\n",
    "    # =========================================================================\n",
    "    print(\"\\n[4] Splitting data into train/validation...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_encoded,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. 모델 학습 (LightGBM) - 콜백 방식 조기 종료\n",
    "    # =========================================================================\n",
    "    print(\"\\n[5] Training LightGBM model...\")\n",
    "    lgb_model = LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=50),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    val_preds_proba = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    val_preds = (val_preds_proba >= 0.5).astype(int)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. 모델 평가\n",
    "    # =========================================================================\n",
    "    print(\"\\n[6] Evaluation on validation set...\")\n",
    "    val_auc = roc_auc_score(y_val, val_preds_proba)\n",
    "    print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "    print(\"\\n[Classification Report]\")\n",
    "    print(classification_report(y_val, val_preds, digits=4))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. 파라미터 튜닝 (GridSearchCV)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[7] Hyperparameter Tuning with GridSearchCV...\")\n",
    "    param_grid = {\n",
    "        'num_leaves': [31, 63],\n",
    "        'max_depth': [-1, 7],\n",
    "        'min_child_samples': [20, 50],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=LGBMClassifier(n_estimators=200, learning_rate=0.03, random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best AUC:\", grid.best_score_)\n",
    "    \n",
    "    # 최적 파라미터로 'n_estimators=1000' 재학습 (콜백 적용)\n",
    "    best_params = grid.best_params_\n",
    "    lgb_model = LGBMClassifier(\n",
    "        **best_params,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.03,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=50),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. 최종 예측 (Test Data) 및 제출 파일 생성\n",
    "    # =========================================================================\n",
    "    print(\"\\n[8] Final Inference & Create Submission File...\")\n",
    "    test_preds_proba = lgb_model.predict_proba(X_test_pre)[:, 1]\n",
    "    submission[\"probability\"] = test_preds_proba\n",
    "    save_path = r\"/Users/chelsey/Desktop/project/lgaimers/tab-transformer-pytorch/data/sample_submission.csv\"\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    print(f\"Submission saved -> {save_path}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 9. (선택) 피처 중요도 시각화\n",
    "    # =========================================================================\n",
    "    print(\"\\n[9] Plot Feature Importances...\")\n",
    "    importances = lgb_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.head(20))\n",
    "    plt.title(\"Top 20 Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
